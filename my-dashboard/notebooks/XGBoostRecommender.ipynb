{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a085483-a6e1-4bfa-acce-7a34cd0cf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "RISK_FREE = 0.043  # 4.3% annual\n",
    "\n",
    "def portfolio_return(weights, mu):\n",
    "    \"\"\"Annualised expected return.\"\"\"\n",
    "    return np.dot(weights, mu)\n",
    "\n",
    "def portfolio_vol(weights, cov):\n",
    "    \"\"\"Annualised volatility (std dev).\"\"\"\n",
    "    return np.sqrt(weights @ cov @ weights)\n",
    "\n",
    "def sharpe_ratio(weights, mu, cov):\n",
    "    \"\"\"Sharpe ratio: (E[R] - Rf) / σ.\"\"\"\n",
    "    ret = portfolio_return(weights, mu)\n",
    "    vol = portfolio_vol(weights, cov)\n",
    "    return (ret - RISK_FREE) / vol\n",
    "\n",
    "def cvar_calc(weights, mu, cov, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Approximate CVaR under Normal assumption:\n",
    "      CVaR = -(mean - σ * φ(Ζα)/(1-α))\n",
    "    where Ζα = norm.ppf(α)\n",
    "    \"\"\"\n",
    "    ret = portfolio_return(weights, mu)\n",
    "    vol = portfolio_vol(weights, cov)\n",
    "    z = st.norm.ppf(alpha)\n",
    "    pdf = st.norm.pdf(z)\n",
    "    cvar = -(ret - vol * pdf / (1 - alpha))\n",
    "    return cvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20099c8a-4233-4c92-8aea-32e26bd41239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def mean_variance_opt(mu, cov, target_return):\n",
    "    \"\"\"\n",
    "    Solve:\n",
    "      minimize 0.5 w^T Σ w\n",
    "      s.t.     μ^T w >= target_return\n",
    "               sum(w) = 1\n",
    "               w >= 0\n",
    "    Returns optimal weights as a NumPy array.\n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    P = matrix(cov * 2)                 # 2Σ\n",
    "    q = matrix(np.zeros(n))             # zero vector\n",
    "\n",
    "    # Constraints Gx <= h  <=>  -Ix <= 0  (w >= 0)\n",
    "    G = matrix(-np.eye(n))\n",
    "    h = matrix(np.zeros(n))\n",
    "\n",
    "    # Constraints Ax = b for equalities and inequalities combined\n",
    "    # We'll stack [1^T; μ^T] for equalities, then the inequality μ^T w >= target => -μ^T w <= -target\n",
    "    A = matrix(np.vstack([np.ones((1, n)), mu.reshape(1, n)]))\n",
    "    b = matrix([1.0, target_return])\n",
    "\n",
    "    # To handle μ^T w >= target, we include it as an inequality by appending to G,h:\n",
    "    # -μ^T w <= -target → G = [ -I; -μ ]  and  h = [ 0; -target ]\n",
    "    G = matrix(np.vstack([np.eye(n)*-1, mu.reshape(1,n)*-1]))\n",
    "    h = matrix(np.hstack([np.zeros(n), -target_return]))\n",
    "\n",
    "    sol = solvers.qp(P, q, G, h, A, b)\n",
    "    w = np.array(sol['x']).flatten()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23bc4af7-5884-40bc-822d-1363e61bea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, requests, time, itertools, math\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "API_KEY = os.getenv(\"ALPHA_VANTAGE_KEY\")\n",
    "BASE    = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "# 10-ticker “mini-universe” (7 blue-chip stocks + 3 broad ETFs)\n",
    "UNIVERSE = [\n",
    "    # 7 Stocks\n",
    "    \"AMZN\",\"GOOG\",\n",
    "    \"BRK.B\",\"JPM\",\n",
    "    \"MA\",\"XOM\",\n",
    "    \"CVX\",\n",
    "\n",
    "    # 3 ETFs\n",
    "    \"SPY\", \"VTI\",\"AGG\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79bfb73-3f3b-4a0b-9329-22b1bee7a258",
   "metadata": {},
   "source": [
    " ## Fetch weekly‐adjusted prices (cache locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0940157b-9ed5-42c0-a06d-2ae75c810185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "CACHE = Path(\"av_cache\"); CACHE.mkdir(exist_ok=True)\n",
    "\n",
    "def av_get(function, symbol):\n",
    "    key = f\"{function}_{symbol}.json\"\n",
    "    fp = CACHE / key\n",
    "    if fp.exists():\n",
    "        return json.loads(fp.read_text())\n",
    "    url = f\"{BASE}?function={function}&symbol={symbol}&apikey={API_KEY}\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    fp.write_text(r.text)\n",
    "    time.sleep(12)                       # AV free tier = 5 calls/min\n",
    "    return r.json()\n",
    "\n",
    "def weekly_series(sym):\n",
    "    js = av_get(\"TIME_SERIES_WEEKLY_ADJUSTED\", sym)\n",
    "    df = (pd.DataFrame(js[\"Weekly Adjusted Time Series\"])\n",
    "            .T.astype(float)[[\"4. close\", \"7. dividend amount\"]].rename(columns={\"4. close\":\"close\", \"7. dividend amount\": \"div\"}))\n",
    "    return df.sort_index()\n",
    "\n",
    "def ttm_div_yield_from_weekly(sym, weeks=52):\n",
    "    \"\"\"\n",
    "    12-month dividend yield using WEEKLY adjusted data.\n",
    "    - Sums the last `weeks` of dividend amounts (cash).\n",
    "    - Divides by the latest close.\n",
    "    - Returns 0.0 for non-payers or missing data.\n",
    "    \"\"\"\n",
    "    df = weekly_series(sym)\n",
    "    if df.empty or \"close\" not in df:\n",
    "        return 0.0\n",
    "\n",
    "    last_close = float(df[\"close\"].iloc[-1])\n",
    "    if not np.isfinite(last_close) or last_close <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    div_sum = float(df.get(\"div\", 0.0).tail(min(weeks, len(df))).sum())\n",
    "    if not np.isfinite(div_sum) or div_sum < 0:\n",
    "        return 0.0\n",
    "\n",
    "    return float(div_sum / last_close)  # e.g., 0.018 = 1.8%\n",
    "    \n",
    "def overview(sym):\n",
    "    return av_get(\"OVERVIEW\", sym)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c5364-e784-43e3-bb5a-c881b60542f8",
   "metadata": {},
   "source": [
    "## Unified Price Table and Momentum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762c22f5-cb25-460c-9495-9ddeb5344b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/gyry33gn15d83nx1ntkgpqg80000gn/T/ipykernel_3253/1920037014.py:9: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  rets   = prices.pct_change().dropna()\n",
      "/var/folders/7w/gyry33gn15d83nx1ntkgpqg80000gn/T/ipykernel_3253/1920037014.py:14: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  mom_6  = prices.pct_change(26).iloc[-1]\n",
      "/var/folders/7w/gyry33gn15d83nx1ntkgpqg80000gn/T/ipykernel_3253/1920037014.py:15: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  mom_12 = prices.pct_change(52).iloc[-1]\n"
     ]
    }
   ],
   "source": [
    "price_dfs = {}\n",
    "for sym in UNIVERSE:\n",
    "    try:\n",
    "        price_dfs[sym] = weekly_series(sym)[\"close\"]\n",
    "    except Exception as e:\n",
    "        print(\"skip\", sym, e)\n",
    "\n",
    "prices = pd.concat(price_dfs, axis=1).dropna(how=\"all\")\n",
    "rets   = prices.pct_change().dropna()\n",
    "μ      = rets.mean() * 52                        # annualised mean\n",
    "Σ      = rets.cov()  * 52                        # annualised cov\n",
    "\n",
    "# Momentum 6m / 12m\n",
    "mom_6  = prices.pct_change(26).iloc[-1]\n",
    "mom_12 = prices.pct_change(52).iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74ffa8aa-9a09-4050-8b02-0f483d718a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMZN': 1999-11-12     74.94\n",
       " 1999-11-19     77.94\n",
       " 1999-11-26     93.13\n",
       " 1999-12-03     86.56\n",
       " 1999-12-10    106.70\n",
       "                ...  \n",
       " 2025-07-25    231.44\n",
       " 2025-08-01    214.75\n",
       " 2025-08-08    222.69\n",
       " 2025-08-15    231.03\n",
       " 2025-08-19    228.01\n",
       " Name: close, Length: 1346, dtype: float64,\n",
       " 'GOOG': 2014-04-04    543.14\n",
       " 2014-04-11    530.60\n",
       " 2014-04-17    536.10\n",
       " 2014-04-25    516.18\n",
       " 2014-05-02    527.93\n",
       "                ...  \n",
       " 2025-07-25    194.08\n",
       " 2025-08-01    189.95\n",
       " 2025-08-08    202.09\n",
       " 2025-08-15    204.91\n",
       " 2025-08-21    200.62\n",
       " Name: close, Length: 595, dtype: float64,\n",
       " 'BRK.B': 1999-11-12    1968.00\n",
       " 1999-11-19    1855.00\n",
       " 1999-11-26    1883.00\n",
       " 1999-12-03    1840.00\n",
       " 1999-12-10    1787.00\n",
       "                ...   \n",
       " 2025-07-25     484.07\n",
       " 2025-08-01     472.84\n",
       " 2025-08-08     465.40\n",
       " 2025-08-15     477.20\n",
       " 2025-08-21     488.59\n",
       " Name: close, Length: 1346, dtype: float64,\n",
       " 'JPM': 1999-11-12     85.00\n",
       " 1999-11-19     83.00\n",
       " 1999-11-26     79.06\n",
       " 1999-12-03     82.00\n",
       " 1999-12-10     78.94\n",
       "                ...  \n",
       " 2025-07-25    298.62\n",
       " 2025-08-01    289.37\n",
       " 2025-08-08    288.76\n",
       " 2025-08-15    290.49\n",
       " 2025-08-21    291.47\n",
       " Name: close, Length: 1346, dtype: float64,\n",
       " 'MA': 2006-06-02     46.99\n",
       " 2006-06-09     47.91\n",
       " 2006-06-16     45.02\n",
       " 2006-06-23     46.95\n",
       " 2006-06-30     48.00\n",
       "                ...  \n",
       " 2025-07-25    568.22\n",
       " 2025-08-01    559.89\n",
       " 2025-08-08    574.32\n",
       " 2025-08-15    581.70\n",
       " 2025-08-21    591.92\n",
       " Name: close, Length: 1004, dtype: float64,\n",
       " 'XOM': 1999-11-12     77.87\n",
       " 1999-11-19     79.69\n",
       " 1999-11-26     78.00\n",
       " 1999-12-03     82.53\n",
       " 1999-12-10     82.81\n",
       "                ...  \n",
       " 2025-07-25    110.40\n",
       " 2025-08-01    109.64\n",
       " 2025-08-08    106.80\n",
       " 2025-08-15    106.49\n",
       " 2025-08-21    109.23\n",
       " Name: close, Length: 1346, dtype: float64,\n",
       " 'CVX': 1999-11-12     91.38\n",
       " 1999-11-19     93.19\n",
       " 1999-11-26     89.00\n",
       " 1999-12-03     90.94\n",
       " 1999-12-10     90.75\n",
       "                ...  \n",
       " 2025-07-25    154.84\n",
       " 2025-08-01    151.40\n",
       " 2025-08-08    155.01\n",
       " 2025-08-15    156.55\n",
       " 2025-08-21    155.55\n",
       " Name: close, Length: 1346, dtype: float64,\n",
       " 'SPY': 1999-11-12    139.7500\n",
       " 1999-11-19    142.5000\n",
       " 1999-11-26    141.4375\n",
       " 1999-12-03    143.8437\n",
       " 1999-12-10    141.8750\n",
       "                 ...   \n",
       " 2025-07-25    637.1000\n",
       " 2025-08-01    621.7200\n",
       " 2025-08-08    637.1800\n",
       " 2025-08-15    643.4400\n",
       " 2025-08-21    635.5500\n",
       " Name: close, Length: 1346, dtype: float64,\n",
       " 'VTI': 2001-06-08    116.40\n",
       " 2001-06-15    111.30\n",
       " 2001-06-22    112.30\n",
       " 2001-06-29    113.00\n",
       " 2001-07-06    109.00\n",
       "                ...  \n",
       " 2025-07-25    313.69\n",
       " 2025-08-01    305.74\n",
       " 2025-08-08    313.03\n",
       " 2025-08-15    316.47\n",
       " 2025-08-21    312.76\n",
       " Name: close, Length: 1264, dtype: float64,\n",
       " 'AGG': 2003-10-03    101.75\n",
       " 2003-10-10    102.00\n",
       " 2003-10-17    101.31\n",
       " 2003-10-24    102.15\n",
       " 2003-10-31    101.74\n",
       "                ...  \n",
       " 2025-07-25     98.45\n",
       " 2025-08-01     99.14\n",
       " 2025-08-08     98.94\n",
       " 2025-08-15     98.94\n",
       " 2025-08-21     98.85\n",
       " Name: close, Length: 1143, dtype: float64}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b148385-d1a4-4f32-8fa3-6fa6d1a501b1",
   "metadata": {},
   "source": [
    "## Fundamental Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83129ded-0d3a-4766-9400-e6f55c8ed374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/gyry33gn15d83nx1ntkgpqg80000gn/T/ipykernel_3253/3128305470.py:31: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  rets = prices[[sym, market]].pct_change().dropna()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Weekly Adjusted Time Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m fund_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sym \u001b[38;5;129;01min\u001b[39;00m UNIVERSE:\n\u001b[0;32m---> 52\u001b[0m     last_close \u001b[38;5;241m=\u001b[39m \u001b[43mlast_close_from_weekly\u001b[49m\u001b[43m(\u001b[49m\u001b[43msym\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     divy_ttm \u001b[38;5;241m=\u001b[39m ttm_div_yield_from_weekly(sym)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_etf(sym):\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;66;03m# ETF branch: sector fixed, shares outstanding from ETF_PROFILE (if present)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[43], line 10\u001b[0m, in \u001b[0;36mlast_close_from_weekly\u001b[0;34m(sym)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlast_close_from_weekly\u001b[39m(sym):\n\u001b[0;32m---> 10\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mweekly_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43msym\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "Cell \u001b[0;32mIn[42], line 17\u001b[0m, in \u001b[0;36mweekly_series\u001b[0;34m(sym)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mweekly_series\u001b[39m(sym):\n\u001b[1;32m     16\u001b[0m     js \u001b[38;5;241m=\u001b[39m av_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTIME_SERIES_WEEKLY_ADJUSTED\u001b[39m\u001b[38;5;124m\"\u001b[39m, sym)\n\u001b[0;32m---> 17\u001b[0m     df \u001b[38;5;241m=\u001b[39m (pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mjs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWeekly Adjusted Time Series\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. close\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7. dividend amount\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. close\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7. dividend amount\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m}))\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39msort_index()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Weekly Adjusted Time Series'"
     ]
    }
   ],
   "source": [
    "def etf_profile(sym):\n",
    "    \"\"\"\n",
    "    Try Alpha Vantage ETF profile (cached via av_get just like other calls).\n",
    "    If unavailable, return {}. Endpoint name is 'ETF_PROFILE'.\n",
    "    \"\"\"\n",
    "    return av_get(\"ETF_PROFILE\", sym)\n",
    "    \n",
    "\n",
    "def last_close_from_weekly(sym):\n",
    "    df = weekly_series(sym)\n",
    "    if df.empty or \"close\" not in df:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(df[\"close\"].iloc[-1])\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def is_etf(sym):\n",
    "    print(bool(etf_profile(sym)))\n",
    "    return bool(etf_profile(sym))\n",
    "    \n",
    "   \n",
    "\n",
    "def compute_beta_from_prices(sym, prices, market = \"SPY\"):\n",
    "    \"\"\"\n",
    "    Estimate beta from weekly returns vs a market proxy (default SPY) using OLS slope.\n",
    "    Returns np.nan if not enough data.\n",
    "    \"\"\"\n",
    "    if sym not in prices or market not in prices:\n",
    "        return np.nan\n",
    "    rets = prices[[sym, market]].pct_change().dropna()\n",
    "    if len(rets) < 12:\n",
    "        return np.nan\n",
    "    x = rets[market].values\n",
    "    y = rets[sym].values\n",
    "    denom = np.dot(x, x)\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return float(np.dot(x, y) / denom)\n",
    "\n",
    "def _to_float(x):\n",
    "    try:\n",
    "        if x in (None, \"None\", \"\", \"NaN\"):\n",
    "            return np.nan\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "fund_rows = []\n",
    "for sym in UNIVERSE:\n",
    "    last_close = last_close_from_weekly(sym)\n",
    "    divy_ttm = ttm_div_yield_from_weekly(sym)\n",
    "    \n",
    "    if is_etf(sym):\n",
    "        # ETF branch: sector fixed, shares outstanding from ETF_PROFILE (if present)\n",
    "        prof = etf_profile(sym) \n",
    "        shares_out = _to_float(prof.get(\"SharesOutstanding\"))\n",
    "        # Market cap = shares * price (if both available)\n",
    "        mcap = shares_out * last_close if np.isfinite(shares_out) and np.isfinite(last_close) else np.nan\n",
    "        logcap = math.log(mcap) if np.isfinite(mcap) and mcap > 0 else np.nan\n",
    "        # ETF beta: try OVERVIEW beta if present (some AV ETFs include it), else estimate from prices vs SPY\n",
    "        beta = compute_beta_from_prices(sym, prices, market=\"SPY\")    \n",
    "        sector = \"ETF\"\n",
    "    else:\n",
    "        o = overview(sym)\n",
    "        beta     = _to_float(o.get(\"Beta\"))\n",
    "        mcap     = _to_float(o.get(\"MarketCapitalization\"))\n",
    "        logcap   = math.log(mcap) if np.isfinite(mcap) and mcap > 0 else np.nan\n",
    "        sector   = o.get(\"Sector\") or \"N/A\"\n",
    "\n",
    "     # 1) ALWAYS append a row (no try/except swallow)\n",
    "    fund_rows.append({\n",
    "        \"ticker\":   sym,\n",
    "        \"beta\":     beta,\n",
    "        \"divYield\": divy_ttm,\n",
    "        \"logCap\":   logcap,\n",
    "        \"sector\":   sector,\n",
    "    })\n",
    "\n",
    "\n",
    "fund = pd.DataFrame(fund_rows).set_index(\"ticker\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16f06024-62c0-455f-9916-3c1bee25d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Information': 'We have detected your API key as None and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_get(\"TIME_SERIES_WEEKLY_ADJUSTED\", 'BRK-B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f542e7b-e1bb-450b-a63d-069044e66e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Information': 'We have detected your API key as P8DFNFHFJTNUZ8CP and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "url = 'https://www.alphavantage.co/query?function=&symbol=BRK.B&apikey=P8DFNFHFJTNUZ8CP'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8eb75c6-bc31-4ac9-a7e9-6f4ceef9e9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>divYield</th>\n",
       "      <th>logCap</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.519613</td>\n",
       "      <td>TRADE &amp; SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1.014</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>28.524157</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPM</th>\n",
       "      <td>1.107</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>27.406930</td>\n",
       "      <td>FINANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>1.029</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>26.994837</td>\n",
       "      <td>TRADE &amp; SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>26.850044</td>\n",
       "      <td>ENERGY &amp; TRANSPORTATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVX</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.043459</td>\n",
       "      <td>26.447676</td>\n",
       "      <td>ENERGY &amp; TRANSPORTATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beta  divYield     logCap                   sector\n",
       "ticker                                                     \n",
       "AMZN    1.314  0.000000  28.519613         TRADE & SERVICES\n",
       "GOOG    1.014  0.004037  28.524157               TECHNOLOGY\n",
       "JPM     1.107  0.018184  27.406930                  FINANCE\n",
       "MA      1.029  0.004967  26.994837         TRADE & SERVICES\n",
       "XOM     0.502  0.036254  26.850044  ENERGY & TRANSPORTATION\n",
       "CVX     0.841  0.043459  26.447676  ENERGY & TRANSPORTATION"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1a48e-332b-4e0b-b123-b3ed5a69ea23",
   "metadata": {},
   "source": [
    "## Building Training Data via Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d03aceae-8b5a-47c4-b640-077f1f474ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrecords = []\\nTARGETS = [0.08, 0.13, 0.18, 0.20, 0.25]  # 8%, 13%, 18%, 20%, 25%\\n\\nfor port in simulate_portfolios():\\n    held = set(port)\\n    base_tickers = list(port.keys())\\n    base_w = np.array(list(port.values()))\\n\\n    # compute base Sharpe/CVaR once per portfolio\\n    base_sh = sharpe_ratio(\\n        base_w,\\n        μ[base_tickers].values,\\n        Σ.loc[base_tickers, base_tickers].values\\n    )\\n    base_cv = cvar_calc(\\n        base_w,\\n        μ[base_tickers].values,\\n        Σ.loc[base_tickers, base_tickers].values\\n    )\\n\\n    for target in TARGETS:\\n        # compute the global optimum for this target\\n        # note: mean_variance_opt solves for w* s.t. sum(w*)=1, w*>=0, μ·w*>=target\\n        w_star = mean_variance_opt(\\n            mu=μ.values,\\n            cov=Σ.values,\\n            target_return=target\\n        )\\n\\n        # map w_star back to ticker list\\n        # assume UNIVERSAL ordering same as μ.index\\n        # so w_star[i] corresponds to μ.index[i]\\n        # heldIdx = [i for i,sym in enumerate(μ.index) if sym in base_tickers]\\n\\n        for cand in fund.index:\\n            if cand in held:\\n                continue\\n\\n            # marginal tilt of ε=1%\\n            eps = 0.01\\n            # take eps from the largest weight in w_star\\n            donor = np.argmax(w_star)\\n            w_pert = w_star.copy()\\n            w_pert[donor] = max(0, w_pert[donor] - eps)\\n            idx = list(μ.index).index(cand)\\n            w_pert[idx] += eps\\n\\n            # compute perturbed metrics\\n            pert_sh = sharpe_ratio(\\n                w_pert,\\n                μ.values,\\n                Σ.values\\n            )\\n            pert_cv = cvar_calc(\\n                w_pert,\\n                μ.values,\\n                Σ.values\\n            )\\n\\n            rec = {\\n                \"ticker\":      cand,\\n                \"targetReturn\": target,\\n                \"deltaSharpe\":  pert_sh - base_sh,\\n                \"deltaCvar\":    base_cv - pert_cv,\\n                \"mom6\":         mom_6[cand],\\n                \"mom12\":        mom_12[cand],\\n                **fund.loc[cand].to_dict(),\\n                \"label\":        label_asset(port, cand, target)\\n            }\\n            records.append(rec)\\n\\ndf = pd.DataFrame(records).dropna()\\n# include \\'targetReturn\\' among features\\nfeature_cols = [\\n    \"deltaSharpe\",\"deltaCvar\",\"mom6\",\"mom12\",\\n    \"beta\",\"divYield\",\"logCap\",\"targetReturn\"\\n]\\nX = df[feature_cols]\\ny = df[\"label\"]\\n\\n# train/val/test split as before\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_temp, y_train, y_temp = train_test_split(\\n    X, y, test_size=0.3, random_state=42, stratify=y\\n)\\nX_val, X_test, y_val, y_test = train_test_split(\\n    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\\n)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def simulate_portfolios(num=2000, size=None, k_frac = (0.2, 0.6), rng_seed = 0):\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    universe = list(dict.fromkeys(UNIVERSE))\n",
    "    N = len(universe) \n",
    "    \n",
    "    if size is None:\n",
    "        k_min = max(3, int(np.ceil(k_frac[0] * N)))\n",
    "        k_max = max(k_min, min(N, int(np.floor(k_frac[1] * N))))\n",
    "        ks = rng.integers(k_min, k_max + 1, size=num)\n",
    "    else:\n",
    "        k_fixed = min(int(size), N)\n",
    "        ks = np.full(num, k_fixed, dtype=int)\n",
    "                     \n",
    "    sims = []\n",
    "    for k in ks:\n",
    "        basket = rng.choice(universe, size=k, replace=False)\n",
    "        w0     = rng.dirichlet(np.ones(k))\n",
    "        sims.append(dict(zip(basket, w0)))\n",
    "    return sims\n",
    "\n",
    "def label_asset(port, asset, target, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Returns 1 if, at the given target return, adding `asset` and re-optimizing\n",
    "    the *basket+asset* portfolio raises Sharpe above the current basket Sharpe\n",
    "    by more than `tol`. Else 0.\n",
    "    \"\"\"\n",
    "    # build the current basket + candidate\n",
    "    basket  = list(port.keys()) + [asset]\n",
    "    w0      = np.append(list(port.values()), 0.0)  # current basket, 0 weight for new asset\n",
    "\n",
    "    # slice μ and Σ to the combined basket (convert to numpy arrays)\n",
    "    mu_b    = μ[basket].values\n",
    "    cov_b   = Σ.loc[basket, basket].values\n",
    "    # small ridge to avoid singular KKT / make SPD\n",
    "    cov_b   = cov_b + 1e-6 * np.eye(cov_b.shape[0])\n",
    "\n",
    "    # baseline Sharpe for the existing basket only (exclude the last asset)\n",
    "    base = sharpe_ratio(\n",
    "        w0[:-1],\n",
    "        mu_b[:-1],\n",
    "        cov_b[:-1, :-1]\n",
    "    )\n",
    "\n",
    "    # optimal weights for basket+asset at this target\n",
    "    w_opt = mean_variance_opt(\n",
    "        mu=mu_b,\n",
    "        cov=cov_b,\n",
    "        target_return=target\n",
    "    )\n",
    "\n",
    "    # if solver fails or returns None/NaNs, treat as no improvement\n",
    "    if w_opt is None or not np.all(np.isfinite(w_opt)):\n",
    "        return 0\n",
    "\n",
    "    new = sharpe_ratio(w_opt, mu_b, cov_b)\n",
    "    return int(new > base + tol)\n",
    "\n",
    "\n",
    "\n",
    "# --- build dataset (fast) ---\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# silence solver logs (if using cvxopt)\n",
    "try:\n",
    "    import cvxopt\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "TARGETS = [0.08, 0.13, 0.18, 0.20, 0.25]\n",
    "\n",
    "# common precomputations\n",
    "mu_vec = μ.values\n",
    "N      = len(mu_vec)\n",
    "Sigma  = Σ.values + 1e-6*np.eye(N)                 # ridge once for stability\n",
    "idx_of = {t: i for i, t in enumerate(μ.index)}     # ticker -> index\n",
    "\n",
    "# 1) global optimum per target (solve QP once per target)\n",
    "w_star_by = {tr: mean_variance_opt(mu=mu_vec, cov=Sigma, target_return=tr)\n",
    "             for tr in TARGETS}\n",
    "\n",
    "# 2) perturbed Sharpe/CVaR per (target, candidate) (compute once, reuse)\n",
    "eps = 0.01\n",
    "pert_by = {}  # (tr, ticker) -> (pert_sh, pert_cv)\n",
    "for tr, w_star in w_star_by.items():\n",
    "    donor  = int(np.argmax(w_star))\n",
    "    donor2 = int(np.argsort(w_star)[-2]) if N >= 2 else donor\n",
    "    for cand in fund.index:\n",
    "        j = idx_of[cand]\n",
    "        d = donor2 if j == donor else donor\n",
    "        w = w_star.copy()\n",
    "        w[d] = max(0.0, w[d] - eps)\n",
    "        w[j] += eps\n",
    "        pert_by[(tr, cand)] = (\n",
    "            sharpe_ratio(w, mu_vec, Sigma),\n",
    "            cvar_calc(w, mu_vec, Sigma),\n",
    "        )\n",
    "\n",
    "# 3) build records using the precomputed pieces\n",
    "records = []\n",
    "for port in simulate_portfolios():  \n",
    "    held          = set(port)\n",
    "    base_tickers  = list(port.keys())\n",
    "    base_w        = np.array(list(port.values()))\n",
    "\n",
    "    mu_b  = μ[base_tickers].values\n",
    "    cov_b = Σ.loc[base_tickers, base_tickers].values + 1e-6*np.eye(len(base_tickers))\n",
    "\n",
    "    base_sh = sharpe_ratio(base_w, mu_b, cov_b)\n",
    "    base_cv = cvar_calc(base_w, mu_b, cov_b)\n",
    "    base_ret = float(np.dot(base_w, μ[base_tickers].values))\n",
    "    base_var = float(base_w @ Σ.loc[base_tickers, base_tickers].values @ base_w)\n",
    "    base_vol = float(np.sqrt(max(base_var, 1e-12)))\n",
    "    \n",
    "    for tr in TARGETS:\n",
    "        for cand in fund.index:\n",
    "            if cand in held:\n",
    "                continue\n",
    "            pert_sh, pert_cv = pert_by[(tr, cand)]\n",
    "            cov_vec  = Σ.loc[base_tickers, cand].values          # covariances with current holdings\n",
    "            cand_var = float(Σ.loc[cand, cand])\n",
    "            cand_vol = float(np.sqrt(max(cand_var, 1e-12)))\n",
    "            portCandCorr = float((base_w @ cov_vec) / ((base_vol + 1e-12) * (cand_vol + 1e-12)))\n",
    "            \n",
    "            records.append({\n",
    "                \"ticker\":        cand,\n",
    "                \"targetReturn\":  tr,\n",
    "                \"deltaSharpe\":   pert_sh - base_sh,\n",
    "                \"deltaCvar\":     base_cv - pert_cv,\n",
    "                \"mom6\":          mom_6[cand],\n",
    "                \"mom12\":         mom_12[cand],\n",
    "                **fund.loc[cand].to_dict(),\n",
    "                \"targetGap\":     float(tr - base_ret),\n",
    "                \"portCandCorr\":  portCandCorr,\n",
    "                \"label\":         label_asset(port, cand, tr), \n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(records).dropna()\n",
    "\n",
    "feature_cols = [\n",
    "    \"deltaSharpe\",\"deltaCvar\",\n",
    "    \"mom6\",\"mom12\",\"beta\",\"divYield\",\"logCap\",\n",
    "    \"targetGap\",\"portCandCorr\",\n",
    "    \"targetReturn\",\n",
    "]\n",
    "X = df[feature_cols].astype(float)\n",
    "\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "'''\n",
    "records = []\n",
    "TARGETS = [0.08, 0.13, 0.18, 0.20, 0.25]  # 8%, 13%, 18%, 20%, 25%\n",
    "\n",
    "for port in simulate_portfolios():\n",
    "    held = set(port)\n",
    "    base_tickers = list(port.keys())\n",
    "    base_w = np.array(list(port.values()))\n",
    "\n",
    "    # compute base Sharpe/CVaR once per portfolio\n",
    "    base_sh = sharpe_ratio(\n",
    "        base_w,\n",
    "        μ[base_tickers].values,\n",
    "        Σ.loc[base_tickers, base_tickers].values\n",
    "    )\n",
    "    base_cv = cvar_calc(\n",
    "        base_w,\n",
    "        μ[base_tickers].values,\n",
    "        Σ.loc[base_tickers, base_tickers].values\n",
    "    )\n",
    "\n",
    "    for target in TARGETS:\n",
    "        # compute the global optimum for this target\n",
    "        # note: mean_variance_opt solves for w* s.t. sum(w*)=1, w*>=0, μ·w*>=target\n",
    "        w_star = mean_variance_opt(\n",
    "            mu=μ.values,\n",
    "            cov=Σ.values,\n",
    "            target_return=target\n",
    "        )\n",
    "\n",
    "        # map w_star back to ticker list\n",
    "        # assume UNIVERSAL ordering same as μ.index\n",
    "        # so w_star[i] corresponds to μ.index[i]\n",
    "        # heldIdx = [i for i,sym in enumerate(μ.index) if sym in base_tickers]\n",
    "\n",
    "        for cand in fund.index:\n",
    "            if cand in held:\n",
    "                continue\n",
    "\n",
    "            # marginal tilt of ε=1%\n",
    "            eps = 0.01\n",
    "            # take eps from the largest weight in w_star\n",
    "            donor = np.argmax(w_star)\n",
    "            w_pert = w_star.copy()\n",
    "            w_pert[donor] = max(0, w_pert[donor] - eps)\n",
    "            idx = list(μ.index).index(cand)\n",
    "            w_pert[idx] += eps\n",
    "\n",
    "            # compute perturbed metrics\n",
    "            pert_sh = sharpe_ratio(\n",
    "                w_pert,\n",
    "                μ.values,\n",
    "                Σ.values\n",
    "            )\n",
    "            pert_cv = cvar_calc(\n",
    "                w_pert,\n",
    "                μ.values,\n",
    "                Σ.values\n",
    "            )\n",
    "\n",
    "            rec = {\n",
    "                \"ticker\":      cand,\n",
    "                \"targetReturn\": target,\n",
    "                \"deltaSharpe\":  pert_sh - base_sh,\n",
    "                \"deltaCvar\":    base_cv - pert_cv,\n",
    "                \"mom6\":         mom_6[cand],\n",
    "                \"mom12\":        mom_12[cand],\n",
    "                **fund.loc[cand].to_dict(),\n",
    "                \"label\":        label_asset(port, cand, target)\n",
    "            }\n",
    "            records.append(rec)\n",
    "\n",
    "df = pd.DataFrame(records).dropna()\n",
    "# include 'targetReturn' among features\n",
    "feature_cols = [\n",
    "    \"deltaSharpe\",\"deltaCvar\",\"mom6\",\"mom12\",\n",
    "    \"beta\",\"divYield\",\"logCap\",\"targetReturn\"\n",
    "]\n",
    "X = df[feature_cols]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# train/val/test split as before\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8970b59-7a15-428a-b38c-b5707efa1f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>targetReturn</th>\n",
       "      <th>deltaSharpe</th>\n",
       "      <th>deltaCvar</th>\n",
       "      <th>mom6</th>\n",
       "      <th>mom12</th>\n",
       "      <th>beta</th>\n",
       "      <th>divYield</th>\n",
       "      <th>logCap</th>\n",
       "      <th>sector</th>\n",
       "      <th>targetGap</th>\n",
       "      <th>portCandCorr</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.260819</td>\n",
       "      <td>0.162698</td>\n",
       "      <td>0.164905</td>\n",
       "      <td>0.215069</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>28.524157</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>-0.114288</td>\n",
       "      <td>0.363290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XOM</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.268852</td>\n",
       "      <td>0.162267</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.073851</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>26.850044</td>\n",
       "      <td>ENERGY &amp; TRANSPORTATION</td>\n",
       "      <td>-0.114288</td>\n",
       "      <td>0.377236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.048936</td>\n",
       "      <td>0.118054</td>\n",
       "      <td>0.164905</td>\n",
       "      <td>0.215069</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>28.524157</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>-0.064288</td>\n",
       "      <td>0.363290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XOM</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.054197</td>\n",
       "      <td>0.117587</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.073851</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>26.850044</td>\n",
       "      <td>ENERGY &amp; TRANSPORTATION</td>\n",
       "      <td>-0.064288</td>\n",
       "      <td>0.377236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.066805</td>\n",
       "      <td>0.164905</td>\n",
       "      <td>0.215069</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>28.524157</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>-0.014288</td>\n",
       "      <td>0.363290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32345</th>\n",
       "      <td>CVX</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.103361</td>\n",
       "      <td>-0.036113</td>\n",
       "      <td>-0.019354</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.043459</td>\n",
       "      <td>26.447676</td>\n",
       "      <td>ENERGY &amp; TRANSPORTATION</td>\n",
       "      <td>0.048818</td>\n",
       "      <td>0.444619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32346</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.092662</td>\n",
       "      <td>-0.138437</td>\n",
       "      <td>0.164905</td>\n",
       "      <td>0.215069</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>28.524157</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>0.098818</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32347</th>\n",
       "      <td>JPM</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.093310</td>\n",
       "      <td>-0.138656</td>\n",
       "      <td>0.101341</td>\n",
       "      <td>0.296575</td>\n",
       "      <td>1.107</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>27.406930</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.098818</td>\n",
       "      <td>0.598750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32348</th>\n",
       "      <td>XOM</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.089919</td>\n",
       "      <td>-0.139092</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.073851</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>26.850044</td>\n",
       "      <td>ENERGY &amp; TRANSPORTATION</td>\n",
       "      <td>0.098818</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32349</th>\n",
       "      <td>CVX</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>-0.139239</td>\n",
       "      <td>-0.019354</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.043459</td>\n",
       "      <td>26.447676</td>\n",
       "      <td>ENERGY &amp; TRANSPORTATION</td>\n",
       "      <td>0.098818</td>\n",
       "      <td>0.444619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32350 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker  targetReturn  deltaSharpe  deltaCvar      mom6     mom12   beta  \\\n",
       "0       GOOG          0.08    -0.260819   0.162698  0.164905  0.215069  1.014   \n",
       "1        XOM          0.08    -0.268852   0.162267 -0.018863 -0.073851  0.502   \n",
       "2       GOOG          0.13    -0.048936   0.118054  0.164905  0.215069  1.014   \n",
       "3        XOM          0.13    -0.054197   0.117587 -0.018863 -0.073851  0.502   \n",
       "4       GOOG          0.18     0.056957   0.066805  0.164905  0.215069  1.014   \n",
       "...      ...           ...          ...        ...       ...       ...    ...   \n",
       "32345    CVX          0.20     0.103361  -0.036113 -0.019354  0.051369  0.841   \n",
       "32346   GOOG          0.25     0.092662  -0.138437  0.164905  0.215069  1.014   \n",
       "32347    JPM          0.25     0.093310  -0.138656  0.101341  0.296575  1.107   \n",
       "32348    XOM          0.25     0.089919  -0.139092 -0.018863 -0.073851  0.502   \n",
       "32349    CVX          0.25     0.090121  -0.139239 -0.019354  0.051369  0.841   \n",
       "\n",
       "       divYield     logCap                   sector  targetGap  portCandCorr  \\\n",
       "0      0.004037  28.524157               TECHNOLOGY  -0.114288      0.363290   \n",
       "1      0.036254  26.850044  ENERGY & TRANSPORTATION  -0.114288      0.377236   \n",
       "2      0.004037  28.524157               TECHNOLOGY  -0.064288      0.363290   \n",
       "3      0.036254  26.850044  ENERGY & TRANSPORTATION  -0.064288      0.377236   \n",
       "4      0.004037  28.524157               TECHNOLOGY  -0.014288      0.363290   \n",
       "...         ...        ...                      ...        ...           ...   \n",
       "32345  0.043459  26.447676  ENERGY & TRANSPORTATION   0.048818      0.444619   \n",
       "32346  0.004037  28.524157               TECHNOLOGY   0.098818      0.364500   \n",
       "32347  0.018184  27.406930                  FINANCE   0.098818      0.598750   \n",
       "32348  0.036254  26.850044  ENERGY & TRANSPORTATION   0.098818      0.395822   \n",
       "32349  0.043459  26.447676  ENERGY & TRANSPORTATION   0.098818      0.444619   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "32345      1  \n",
       "32346      1  \n",
       "32347      1  \n",
       "32348      1  \n",
       "32349      1  \n",
       "\n",
       "[32350 rows x 13 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814d754-c069-42b7-9dc6-4dccb452e63e",
   "metadata": {},
   "source": [
    "## Run Grid Search with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcdc50a9-3145-447e-8c3c-b474f821584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best AUC 0.964 with {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 600, 'subsample': 0.9} (best_iter=598)\n",
      "New best AUC 0.966 with {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 600, 'subsample': 0.9} (best_iter=599)\n",
      "New best AUC 0.966 with {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 600, 'subsample': 0.9} (best_iter=599)\n",
      "New best AUC 0.967 with {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 600, 'subsample': 0.9} (best_iter=592)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# handle class imbalance\n",
    "pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\":        [3, 4],\n",
    "    \"learning_rate\":    [0.05, 0.1],\n",
    "    \"n_estimators\":     [600],   # will be cut by early stopping\n",
    "    \"subsample\":        [0.9],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"gamma\":            [0]\n",
    "}\n",
    "\n",
    "best_auc, best_params, best_model = -1, None, None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"auc\",\n",
    "        random_state=42,\n",
    "        scale_pos_weight=float(pos_weight),\n",
    "        early_stopping_rounds=50,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    clf.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "    best_iter = getattr(clf, \"best_iteration\", None)\n",
    "    if best_iter is not None:\n",
    "        y_val_pred = clf.predict_proba(X_val, iteration_range=(0, best_iter + 1))[:, 1]\n",
    "    else:\n",
    "        # fallback if attribute not present\n",
    "        y_val_pred = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "    if auc > best_auc:\n",
    "        best_auc, best_params, best_model = auc, params, clf\n",
    "        print(f\"New best AUC {auc:.3f} with {params} (best_iter={best_iter})\")\n",
    "    '''\n",
    "    auc = roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])\n",
    "    if auc > best_auc:\n",
    "        best_auc, best_params, best_model = auc, params, clf\n",
    "        print(f\"New best AUC {auc:.3f} with {params} (ntree_limit={clf.best_ntree_limit})\")\n",
    "\n",
    "print(\"Best validation AUC:\", best_auc)\n",
    "best_params\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8fe5f43-b1e3-40f1-bf8e-10fc2e393252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 600,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133c27b-8d9e-4a72-96a3-0eae3a455320",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3239223c-edef-4b56-b915-0654d9d285cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.968 | PR-AUC: 0.988\n",
      "Test AUC: 0.968 | PR-AUC: 0.988\n",
      "Thr (from val): 0.640 | Precision: 0.973  Recall: 0.854  F1: 0.910\n",
      "Confusion matrix [tn fp; fn tp]:\n",
      " [[1215   85]\n",
      " [ 518 3035]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from sklearn.metrics import roc_curve, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "proba_test = best_model.predict_proba(X_test)[:,1]\n",
    "auc_test   = roc_auc_score(y_test, proba_test)\n",
    "ap_test    = average_precision_score(y_test, proba_test)\n",
    "print(f\"Test AUC: {auc_test:.3f} | PR-AUC: {ap_test:.3f}\")\n",
    "\n",
    "\n",
    "# pick threshold on VALIDATION by maximizing Youden J\n",
    "proba_val = best_model.predict_proba(X_val)[:, 1]\n",
    "fpr, tpr, thr_grid = roc_curve(y_val, proba_val)\n",
    "j_scores = tpr - fpr\n",
    "thr = thr_grid[j_scores.argmax()]  # best threshold on validation\n",
    "\n",
    "# apply to TEST\n",
    "proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "pred_test = (proba_test >= thr).astype(int)\n",
    "\n",
    "# metrics\n",
    "auc_test = roc_auc_score(y_test, proba_test)\n",
    "ap_test  = average_precision_score(y_test, proba_test)\n",
    "p, r, f1, _ = precision_recall_fscore_support(y_test, pred_test, average=\"binary\", zero_division=0)\n",
    "cm = confusion_matrix(y_test, pred_test)\n",
    "\n",
    "print(f\"Test AUC: {auc_test:.3f} | PR-AUC: {ap_test:.3f}\")\n",
    "print(f\"Thr (from val): {thr:.3f} | Precision: {p:.3f}  Recall: {r:.3f}  F1: {f1:.3f}\")\n",
    "print(\"Confusion matrix [tn fp; fn tp]:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b69fa-91cc-4e95-8dc8-8f8de2d9586c",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3dc77c63-aa06-4ffa-a7da-965358ed54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../src/lib/recommend_model.onnx\n",
      "Saved: ../src/lib/recommend_columns.json\n"
     ]
    }
   ],
   "source": [
    "# --- Save the model (package-agnostic, robust) ---\n",
    "from pathlib import Path\n",
    "import json\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType\n",
    "from onnxmltools.convert.xgboost import convert as convert_xgboost\n",
    "\n",
    "FEATURE_ORDER = [\n",
    "    \"deltaSharpe\",\"deltaCvar\",\"mom6\",\"mom12\",\"beta\",\"divYield\",\"logCap\",\n",
    "    \"targetReturn\",\"targetGap\",\"portCandCorr\",\n",
    "]\n",
    "\n",
    "booster = best_model.get_booster()  # from xgboost.XGBClassifier\n",
    "initial_types = [('input', FloatTensorType([None, len(FEATURE_ORDER)]))]\n",
    "n = len(FEATURE_ORDER)  # same order you use to build X at runtime\n",
    "booster = best_model.get_booster()\n",
    "\n",
    "# Remap feature names to f0..f{n-1} so onnxmltools can parse them\n",
    "booster.feature_names = [f\"f{i}\" for i in range(n)]\n",
    "booster.feature_types = [\"float\"] * n  # keeps it simple\n",
    "\n",
    "onnx_model = convert_xgboost(\n",
    "    booster,\n",
    "    initial_types=[('input', FloatTensorType([None, n]))],\n",
    "    target_opset=13,\n",
    ")\n",
    "\n",
    "\n",
    "out_dir = Path(\"../src/lib\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "(out_dir / \"recommend_model.onnx\").write_bytes(onnx_model.SerializeToString())\n",
    "(out_dir / \"recommend_columns.json\").write_text(json.dumps(FEATURE_ORDER))\n",
    "print(\"Saved:\", out_dir / \"recommend_model.onnx\")\n",
    "print(\"Saved:\", out_dir / \"recommend_columns.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d39230-401c-473a-abdc-b036b658a913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
